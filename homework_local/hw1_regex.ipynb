{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98fee0fe",
   "metadata": {},
   "source": [
    "<div align=right>\n",
    "Winter 2025<br>\n",
    "Nardin<br>\n",
    "HW 1\n",
    "</div>\n",
    "\n",
    "\n",
    "<font color='darkblue'> <h2 align=center> Homework 1: Regular Expressions</h2> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80481409",
   "metadata": {},
   "source": [
    "**Instructions** \n",
    "\n",
    "Write code using regular expressions to find patterns in the text below from Alice in Wonderland. You can use https://regex101.com/ or https://pythex.org/ to test your regex before applying it to your text.\n",
    "\n",
    "Submit on Gradescope your Jupyter notebook with the homework completed and the output of your code visible. Answer all questions.\n",
    "\n",
    "HWs must be completed individually and are graded on a Pass-Fail basis. Before submitting, see the Syllabus for homework policies (what qualifies as a \"Pass\", deadlines, regrading conditions, etc.)\n",
    "\n",
    "At the end of the notebook, list all resources you consulted (e.g., this notebook; if you consult specific websites, please add all links to them; if you use AI, explain for which task you used it and how). Do not submit code you do not fully understand or you have not written yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3b50ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/var/folders/2j/3sx5nt8j6z50m94mxgx048hr0000gn/T/ipykernel_48063/3161059068.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  alice = \"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: \\\n"
     ]
    }
   ],
   "source": [
    "alice = \"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: \\\n",
    "once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, \\\n",
    "'and what is the use of a book,' thought Alice 'without pictures or conversation?' So she was considering in her own mind \\\n",
    "(as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain \\\n",
    "would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\\\n",
    "There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to \\\n",
    "itself, 'Oh dear!  Oh dear!  I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have \\\n",
    "wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually \\\n",
    "TOOK A WATCH OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, Alice started to her feet, \\\n",
    "for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to \\\n",
    "take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop \\\n",
    "down a large rabbit-hole under the hedge. \\\n",
    "In another moment down went Alice after it, never once considering how in the world she was to get out again. \\\n",
    "The rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that \\\n",
    "Alice had not a moment to think about stopping herself before she found herself falling down a very deep well. \\\n",
    "Either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to \\\n",
    "wonder what was going to happen next.  First, she tried to look down and make out what she was coming to, \\\n",
    "but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with \\\n",
    "cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. \\\n",
    "She took down a jar from one of the shelves as she passed; it was labelled `ORANGE MARMALADE', \\\n",
    "but to her great disappointment it was empty:  she did not like to drop the jar for fear of killing somebody, \\\n",
    "so managed to put it into one of the cupboards as she fell past it. \\ \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432e636",
   "metadata": {},
   "source": [
    "Question 1. Find all uppercase words (e.g., VERY, TOOK, etc.) in the provided text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d8a618f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VERY',\n",
       " 'VERY',\n",
       " 'I',\n",
       " 'TOOK',\n",
       " 'A',\n",
       " 'WATCH',\n",
       " 'OUT',\n",
       " 'OF',\n",
       " 'ITS',\n",
       " 'WAISTCOAT',\n",
       " 'POCKET',\n",
       " 'ORANGE',\n",
       " 'MARMALADE']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found help through this stack overflow thread \n",
    "# https://stackoverflow.com/questions/4598315/regex-to-match-only-uppercase-words-with-some-exceptions\n",
    "# Helped me figure out that \\b needs to be used on both ends of the regex statement, not just at the beginning\n",
    "\n",
    "import re \n",
    "re.findall(r'\\b[A-Z]+\\b', alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab0381",
   "metadata": {},
   "source": [
    "Question 2. Find all words that *could be* present progressive verbs (i.e., find anything that ends with \"ing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2ab7cb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beginning',\n",
       " 'sitting',\n",
       " 'having',\n",
       " 'nothing',\n",
       " 'reading',\n",
       " 'considering',\n",
       " 'making',\n",
       " 'getting',\n",
       " 'picking',\n",
       " 'nothing',\n",
       " 'burning',\n",
       " 'considering',\n",
       " 'stopping',\n",
       " 'falling',\n",
       " 'going',\n",
       " 'coming',\n",
       " 'anything',\n",
       " 'killing']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\w*ing', alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e623de",
   "metadata": {},
   "source": [
    "Question 3. Find all words that contain three consonants close to each other and display these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a8e2f47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought',\n",
       " 'worth',\n",
       " 'suddenly',\n",
       " 'thought',\n",
       " 'afterwards',\n",
       " 'ought',\n",
       " 'actually',\n",
       " 'WATCH',\n",
       " 'watch',\n",
       " 'world',\n",
       " 'straight',\n",
       " 'suddenly',\n",
       " 'suddenly',\n",
       " 'slowly',\n",
       " 'plenty',\n",
       " 'First',\n",
       " 'cupboards',\n",
       " 'empty',\n",
       " 'cupboards']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\b[a-zA-Z]+[^aeiouAEIOU -]{3}\\b', alice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6652ef71",
   "metadata": {},
   "source": [
    "Question 4. Find anything that could be the past tense of a regular verb (i.e., anything that ends in \"ed\", etc.), and remove duplicates from your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "636a7bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flashed',\n",
       " 'managed',\n",
       " 'tired',\n",
       " 'dipped',\n",
       " 'tried',\n",
       " 'peeped',\n",
       " 'noticed',\n",
       " 'passed',\n",
       " 'hurried',\n",
       " 'wondered',\n",
       " 'looked',\n",
       " 'started',\n",
       " 'occurred',\n",
       " 'filled',\n",
       " 'labelled',\n",
       " 'seemed']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_words = re.findall(r'\\b\\w+ed\\b', alice)\n",
    "ed_words\n",
    "unique_words = list(set(ed_words))\n",
    "unique_words\n",
    "# print(type(unique_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa5796",
   "metadata": {},
   "source": [
    "Question 5. From the list of words ending in \"ed\" that you found in the previous question, create verb stems by removing the past tense marker. Use only string methods and regular expressions. \n",
    "Note: The goal of this question is to practice using regular expressions and face the challenges of creating a stemmer without advanced NLP tools. Your stemmer is not expected to be 100% precise, but it should show attempts to account for the most common spelling conventions (e.g., \"tired\" should become \"tire,\" not \"tir\"). You can refer to this guide for some spelling rules https://www.rong-chang.com/double_rule.htm and pick a few to implement in your code (e.g., 2 or 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c2132",
   "metadata": {},
   "source": [
    "## Scroll to bottom for final version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7011c23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flash',\n",
       " 'manag',\n",
       " 'tir',\n",
       " 'dipp',\n",
       " 'tri',\n",
       " 'peep',\n",
       " 'notic',\n",
       " 'pass',\n",
       " 'hurri',\n",
       " 'wonder',\n",
       " 'look',\n",
       " 'start',\n",
       " 'occurr',\n",
       " 'fill',\n",
       " 'labell',\n",
       " 'seem']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original w/o list comprehension \n",
    "# unique_words_cleaned = []\n",
    "# for word in unique_words:\n",
    "#     word = re.sub(r'ed$',\"\",word)\n",
    "#     unique_words_cleaned.append(word)\n",
    "# unique_words_cleaned\n",
    "\n",
    "# Adjusted with list comprehnsion \n",
    "unique_words_cleaned = [re.sub(r'ed$', '', word) for word in unique_words]\n",
    "unique_words_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "72fc3222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flash',\n",
       " 'manag',\n",
       " 'tir',\n",
       " 'dipp',\n",
       " 'try',\n",
       " 'peep',\n",
       " 'notic',\n",
       " 'pass',\n",
       " 'hurry',\n",
       " 'wonder',\n",
       " 'look',\n",
       " 'start',\n",
       " 'occurr',\n",
       " 'fill',\n",
       " 'labell',\n",
       " 'seem']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_stems = [re.sub(r'i$', 'y', word) for word in unique_words_cleaned]\n",
    "unique_words_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "97d825e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flash',\n",
       " 'manage',\n",
       " 'tire',\n",
       " 'dipp',\n",
       " 'tri',\n",
       " 'peep',\n",
       " 'notice',\n",
       " 'pass',\n",
       " 'hurri',\n",
       " 'wondere',\n",
       " 'look',\n",
       " 'start',\n",
       " 'occurre',\n",
       " 'fill',\n",
       " 'labell',\n",
       " 'seem']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vowels = ['a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n",
    "# consonants = ['b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z',\n",
    "#               'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "unique_words_stems = [word + 'e' if re.search(r'[rcg]$', word)else word for word in unique_words_cleaned]\n",
    "unique_words_stems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce322b8d",
   "metadata": {},
   "source": [
    "# Final Version for Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1e161d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flash',\n",
       " 'manage',\n",
       " 'tire',\n",
       " 'dip',\n",
       " 'try',\n",
       " 'peep',\n",
       " 'notice',\n",
       " 'pas',\n",
       " 'hurry',\n",
       " 'wonder',\n",
       " 'look',\n",
       " 'start',\n",
       " 'occur',\n",
       " 'fil',\n",
       " 'label',\n",
       " 'seem']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words_cleaned_ed = [re.sub(r'ed$', '', word) for word in unique_words]\n",
    "\n",
    "unique_words_stem_change = []\n",
    "\n",
    "for word in unique_words_cleaned_ed:\n",
    "    if re.search(r'[rcg]$', word) and not re.search(r'(rr|er)$', word):\n",
    "        fixed_word = word + 'e'\n",
    "        unique_words_stem_change.append(fixed_word)\n",
    "    elif re.search(r'i$', word):  \n",
    "        fixed_word = re.sub(r'i$', 'y', word)  \n",
    "        unique_words_stem_change.append(fixed_word)\n",
    "    elif re.search(r'(.)\\1$', word):\n",
    "        fixed_word = word[:-1]\n",
    "        unique_words_stem_change.append(fixed_word)\n",
    "    else:\n",
    "        unique_words_stem_change.append(word)\n",
    "    \n",
    "unique_words_stem_change\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macs30112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
